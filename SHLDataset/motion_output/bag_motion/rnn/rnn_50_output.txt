read h5 file....
Train on 48636 samples, validate on 12159 samples
Epoch 1/50
48636/48636 [==============================] - 31s 647us/sample - loss: 1.0728 - acc: 0.6437 - val_loss: 0.5603 - val_acc: 0.8177
Epoch 2/50
48636/48636 [==============================] - 36s 736us/sample - loss: 0.4213 - acc: 0.8661 - val_loss: 0.3159 - val_acc: 0.8984
Epoch 3/50
48636/48636 [==============================] - 43s 888us/sample - loss: 0.2737 - acc: 0.9140 - val_loss: 0.2621 - val_acc: 0.9175
Epoch 4/50
48636/48636 [==============================] - 34s 694us/sample - loss: 0.2215 - acc: 0.9287 - val_loss: 0.1905 - val_acc: 0.9447
Epoch 5/50
48636/48636 [==============================] - 34s 694us/sample - loss: 0.1941 - acc: 0.9376 - val_loss: 0.1804 - val_acc: 0.9410
Epoch 6/50
48636/48636 [==============================] - 35s 723us/sample - loss: 0.1781 - acc: 0.9412 - val_loss: 0.1687 - val_acc: 0.9480
Epoch 7/50
48636/48636 [==============================] - 36s 736us/sample - loss: 0.1670 - acc: 0.9451 - val_loss: 0.1493 - val_acc: 0.9511
Epoch 8/50
48636/48636 [==============================] - 36s 750us/sample - loss: 0.1578 - acc: 0.9480 - val_loss: 0.1519 - val_acc: 0.9521/48636 [========>.....................] - ETA: 23s - loss: 0.1632 - acc: 0.9472
Epoch 9/50
48636/48636 [==============================] - 39s 803us/sample - loss: 0.1479 - acc: 0.9517 - val_loss: 0.1445 - val_acc: 0.9538
Epoch 10/50
48636/48636 [==============================] - 38s 785us/sample - loss: 0.1422 - acc: 0.9532 - val_loss: 0.1394 - val_acc: 0.9551
Epoch 11/50
48636/48636 [==============================] - 37s 756us/sample - loss: 0.1356 - acc: 0.9560 - val_loss: 0.1288 - val_acc: 0.9590
Epoch 12/50
48636/48636 [==============================] - 36s 741us/sample - loss: 0.1328 - acc: 0.9557 - val_loss: 0.1419 - val_acc: 0.9538
Epoch 13/50
48636/48636 [==============================] - 38s 773us/sample - loss: 0.1252 - acc: 0.9583 - val_loss: 0.1234 - val_acc: 0.9606
Epoch 14/50
48636/48636 [==============================] - 37s 759us/sample - loss: 0.1208 - acc: 0.9591 - val_loss: 0.1331 - val_acc: 0.9559
Epoch 15/50
48636/48636 [==============================] - 37s 757us/sample - loss: 0.1158 - acc: 0.9610 - val_loss: 0.1192 - val_acc: 0.9610
Epoch 16/50
48636/48636 [==============================] - 38s 789us/sample - loss: 0.1122 - acc: 0.9615 - val_loss: 0.1229 - val_acc: 0.9588
Epoch 17/50
48636/48636 [==============================] - 37s 764us/sample - loss: 0.1106 - acc: 0.9626 - val_loss: 0.1017 - val_acc: 0.9681
Epoch 18/50
48636/48636 [==============================] - 38s 784us/sample - loss: 0.1098 - acc: 0.9623 - val_loss: 0.1249 - val_acc: 0.9583- ETA: 27s - loss: 0.1103 - acc: 0.9634
Epoch 19/50
48636/48636 [==============================] - 37s 764us/sample - loss: 0.1053 - acc: 0.9641 - val_loss: 0.1013 - val_acc: 0.9655- ETA: 24s - loss: 0.1027 - acc: 0.9668
Epoch 20/50
48636/48636 [==============================] - 44s 895us/sample - loss: 0.1062 - acc: 0.9641 - val_loss: 0.1043 - val_acc: 0.9655
Epoch 21/50
48636/48636 [==============================] - 41s 842us/sample - loss: 0.1020 - acc: 0.9653 - val_loss: 0.0994 - val_acc: 0.9675
Epoch 22/50
48636/48636 [==============================] - 38s 773us/sample - loss: 0.0980 - acc: 0.9666 - val_loss: 0.1003 - val_acc: 0.9666
Epoch 23/50
48636/48636 [==============================] - 40s 823us/sample - loss: 0.0969 - acc: 0.9663 - val_loss: 0.1143 - val_acc: 0.9585
Epoch 24/50
48636/48636 [==============================] - 38s 781us/sample - loss: 0.0972 - acc: 0.9661 - val_loss: 0.0984 - val_acc: 0.9667
Epoch 25/50
48636/48636 [==============================] - 41s 842us/sample - loss: 0.0926 - acc: 0.9676 - val_loss: 0.0923 - val_acc: 0.9678
Epoch 26/50
48636/48636 [==============================] - 40s 823us/sample - loss: 0.0911 - acc: 0.9681 - val_loss: 0.0873 - val_acc: 0.9715
Epoch 27/50
48636/48636 [==============================] - 37s 769us/sample - loss: 0.0926 - acc: 0.9679 - val_loss: 0.0977 - val_acc: 0.9658
Epoch 28/50
48636/48636 [==============================] - 39s 798us/sample - loss: 0.0896 - acc: 0.9692 - val_loss: 0.0939 - val_acc: 0.9675
Epoch 29/50
48636/48636 [==============================] - 38s 787us/sample - loss: 0.0909 - acc: 0.9686 - val_loss: 0.1051 - val_acc: 0.9647
Epoch 30/50
48636/48636 [==============================] - 38s 785us/sample - loss: 0.0884 - acc: 0.9692 - val_loss: 0.1105 - val_acc: 0.9630
Epoch 31/50
48636/48636 [==============================] - 38s 787us/sample - loss: 0.0841 - acc: 0.9708 - val_loss: 0.1063 - val_acc: 0.9632
Epoch 32/50
48636/48636 [==============================] - 39s 794us/sample - loss: 0.0865 - acc: 0.9692 - val_loss: 0.0988 - val_acc: 0.9646
Epoch 33/50
48636/48636 [==============================] - 38s 782us/sample - loss: 0.0792 - acc: 0.9718 - val_loss: 0.0864 - val_acc: 0.9711
Epoch 34/50
48636/48636 [==============================] - 38s 792us/sample - loss: 0.0861 - acc: 0.9697 - val_loss: 0.1079 - val_acc: 0.9601
Epoch 35/50
48636/48636 [==============================] - 39s 806us/sample - loss: 0.0813 - acc: 0.9712 - val_loss: 0.0897 - val_acc: 0.9692
Epoch 36/50
48636/48636 [==============================] - 38s 791us/sample - loss: 0.0812 - acc: 0.9709 - val_loss: 0.1003 - val_acc: 0.9662
Epoch 37/50
48636/48636 [==============================] - 44s 898us/sample - loss: 0.0762 - acc: 0.9730 - val_loss: 0.0824 - val_acc: 0.9725
Epoch 38/50
48636/48636 [==============================] - 40s 814us/sample - loss: 0.0811 - acc: 0.9711 - val_loss: 0.0910 - val_acc: 0.9682
Epoch 39/50
48636/48636 [==============================] - 38s 785us/sample - loss: 0.0781 - acc: 0.9721 - val_loss: 0.0857 - val_acc: 0.9711
Epoch 40/50
48636/48636 [==============================] - 39s 804us/sample - loss: 0.0765 - acc: 0.9731 - val_loss: 0.0857 - val_acc: 0.9690
Epoch 41/50
48636/48636 [==============================] - 40s 814us/sample - loss: 0.0767 - acc: 0.9721 - val_loss: 0.0828 - val_acc: 0.9732
Epoch 42/50
48636/48636 [==============================] - 38s 773us/sample - loss: 0.0747 - acc: 0.9728 - val_loss: 0.0859 - val_acc: 0.9715- ETA: 3s - loss: 0.0745 - acc: 0.9727
Epoch 43/50
48636/48636 [==============================] - 39s 810us/sample - loss: 0.0750 - acc: 0.9744 - val_loss: 0.1001 - val_acc: 0.9658
Epoch 44/50
48636/48636 [==============================] - 39s 797us/sample - loss: 0.0734 - acc: 0.9741 - val_loss: 0.0842 - val_acc: 0.9696
Epoch 45/50
48636/48636 [==============================] - 39s 811us/sample - loss: 0.0726 - acc: 0.9742 - val_loss: 0.0832 - val_acc: 0.9711
Epoch 46/50
48636/48636 [==============================] - 39s 792us/sample - loss: 0.0695 - acc: 0.9751 - val_loss: 0.0835 - val_acc: 0.9717
Epoch 47/50
48636/48636 [==============================] - 39s 797us/sample - loss: 0.0706 - acc: 0.9746 - val_loss: 0.0716 - val_acc: 0.9761
Epoch 48/50
48636/48636 [==============================] - 40s 831us/sample - loss: 0.0680 - acc: 0.9756 - val_loss: 0.0811 - val_acc: 0.9716
Epoch 49/50
48636/48636 [==============================] - 38s 789us/sample - loss: 0.0684 - acc: 0.9755 - val_loss: 0.0827 - val_acc: 0.9708
Epoch 50/50
48636/48636 [==============================] - 40s 821us/sample - loss: 0.0671 - acc: 0.9762 - val_loss: 0.0877 - val_acc: 0.9705
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_64 (InputLayer)        (None, 20, 22)            0         
_________________________________________________________________
lstm_5 (LSTM)                (None, 20, 128)           77312     
_________________________________________________________________
dense_168 (Dense)            (None, 20, 128)           16512     
_________________________________________________________________
global_max_pooling1d_3 (Glob (None, 128)               0         
_________________________________________________________________
dense_169 (Dense)            (None, 8)                 1032      
=================================================================
Total params: 94,856
Trainable params: 94,856
Non-trainable params: 0
_________________________________________________________________
None
Confusion matrix, without normalization
[[1626   53    3    0    3    1    1  104]
 [   6 1722    2    0    0    0    0    0]
 [   3    0 1601    3    5    0    8    2]
 [   0    0    2  268    0    0    0    0]
 [   7    3    9    0  899    0   19    1]
 [   0    0    1    0    0 2004    9    0]
 [   3   11    5    0    0   19 1938    0]
 [  55   17    3    0    0    1    0 1742]]