Train on 20508 samples, validate on 13673 samples
Epoch 1/50
20508/20508 [==============================] - 130s 6ms/sample - loss: 0.8564 - acc: 0.6688 - val_loss: 0.7751 - val_acc: 0.6999
Epoch 2/50
20508/20508 [==============================] - 127s 6ms/sample - loss: 0.7048 - acc: 0.7266 - val_loss: 0.6803 - val_acc: 0.7430
Epoch 3/50
20508/20508 [==============================] - 134s 7ms/sample - loss: 0.6656 - acc: 0.7407 - val_loss: 0.5913 - val_acc: 0.7770
Epoch 4/50
20508/20508 [==============================] - 116s 6ms/sample - loss: 0.6391 - acc: 0.7502 - val_loss: 0.6473 - val_acc: 0.7456
Epoch 5/50
20508/20508 [==============================] - 119s 6ms/sample - loss: 0.6922 - acc: 0.7316 - val_loss: 0.8129 - val_acc: 0.7062
Epoch 6/50
20508/20508 [==============================] - 119s 6ms/sample - loss: 0.7159 - acc: 0.7207 - val_loss: 0.7045 - val_acc: 0.7175
Epoch 7/50
20508/20508 [==============================] - 107s 5ms/sample - loss: 0.6830 - acc: 0.7343 - val_loss: 0.7128 - val_acc: 0.7188
Epoch 8/50
20508/20508 [==============================] - 104s 5ms/sample - loss: 0.6235 - acc: 0.7549 - val_loss: 0.6308 - val_acc: 0.7596
Epoch 9/50
20508/20508 [==============================] - 104s 5ms/sample - loss: 0.6544 - acc: 0.7406 - val_loss: 0.6171 - val_acc: 0.7561
Epoch 10/50
20508/20508 [==============================] - 122s 6ms/sample - loss: 0.6242 - acc: 0.7597 - val_loss: 0.6278 - val_acc: 0.7722
Epoch 11/50
20508/20508 [==============================] - 124s 6ms/sample - loss: 0.6045 - acc: 0.7665 - val_loss: 0.6542 - val_acc: 0.7453
Epoch 12/50
20508/20508 [==============================] - 128s 6ms/sample - loss: 0.6191 - acc: 0.7580 - val_loss: 0.6699 - val_acc: 0.7470
Epoch 13/50
20508/20508 [==============================] - 115s 6ms/sample - loss: 0.6243 - acc: 0.7595 - val_loss: 0.6367 - val_acc: 0.7443
Epoch 14/50
20508/20508 [==============================] - 116s 6ms/sample - loss: 0.6260 - acc: 0.7588 - val_loss: 0.6637 - val_acc: 0.7488
Epoch 15/50
20508/20508 [==============================] - 118s 6ms/sample - loss: 0.6116 - acc: 0.7637 - val_loss: 0.5891 - val_acc: 0.7867
Epoch 16/50
20508/20508 [==============================] - 122s 6ms/sample - loss: 0.6058 - acc: 0.7686 - val_loss: 0.6183 - val_acc: 0.7670
Epoch 17/50
20508/20508 [==============================] - 121s 6ms/sample - loss: 0.5757 - acc: 0.7835 - val_loss: 0.5594 - val_acc: 0.7932
Epoch 18/50
20508/20508 [==============================] - 116s 6ms/sample - loss: 0.5845 - acc: 0.7776 - val_loss: 0.6014 - val_acc: 0.7598
Epoch 19/50
20508/20508 [==============================] - 126s 6ms/sample - loss: 0.5914 - acc: 0.7684 - val_loss: 0.6052 - val_acc: 0.7680
Epoch 20/50
20508/20508 [==============================] - 115s 6ms/sample - loss: 0.6024 - acc: 0.7658 - val_loss: 0.6015 - val_acc: 0.7654
Epoch 21/50
20508/20508 [==============================] - 114s 6ms/sample - loss: 0.5897 - acc: 0.7727 - val_loss: 0.5557 - val_acc: 0.7880
Epoch 22/50
20508/20508 [==============================] - 119s 6ms/sample - loss: 0.5728 - acc: 0.7769 - val_loss: 0.5966 - val_acc: 0.7684
Epoch 23/50
20508/20508 [==============================] - 122s 6ms/sample - loss: 0.5801 - acc: 0.7777 - val_loss: 0.6277 - val_acc: 0.7593
Epoch 24/50
20508/20508 [==============================] - 120s 6ms/sample - loss: 0.5993 - acc: 0.7679 - val_loss: 0.6447 - val_acc: 0.7582
Epoch 25/50
20508/20508 [==============================] - 112s 5ms/sample - loss: 0.6151 - acc: 0.7664 - val_loss: 0.6869 - val_acc: 0.7222
Epoch 26/50
20508/20508 [==============================] - 110s 5ms/sample - loss: 0.6205 - acc: 0.7583 - val_loss: 0.6515 - val_acc: 0.7494
Epoch 27/50
20508/20508 [==============================] - 115s 6ms/sample - loss: 0.6482 - acc: 0.7451 - val_loss: 0.6779 - val_acc: 0.7331
Epoch 28/50
20508/20508 [==============================] - 114s 6ms/sample - loss: 0.6167 - acc: 0.7594 - val_loss: 0.5736 - val_acc: 0.7821
Epoch 29/50
20508/20508 [==============================] - 116s 6ms/sample - loss: 0.5949 - acc: 0.7652 - val_loss: 0.5802 - val_acc: 0.7663
Epoch 30/50
20508/20508 [==============================] - 123s 6ms/sample - loss: 0.5841 - acc: 0.7729 - val_loss: 0.5849 - val_acc: 0.7677
Epoch 31/50
20508/20508 [==============================] - 107s 5ms/sample - loss: 0.5558 - acc: 0.7881 - val_loss: 0.5765 - val_acc: 0.7736
Epoch 32/50
20508/20508 [==============================] - 103s 5ms/sample - loss: 0.5615 - acc: 0.7831 - val_loss: 0.5435 - val_acc: 0.7908
Epoch 33/50
20508/20508 [==============================] - 105s 5ms/sample - loss: 0.5515 - acc: 0.7851 - val_loss: 0.5687 - val_acc: 0.7736
Epoch 34/50
20508/20508 [==============================] - 105s 5ms/sample - loss: 0.5349 - acc: 0.7901 - val_loss: 0.5197 - val_acc: 0.8034
Epoch 35/50
20508/20508 [==============================] - 104s 5ms/sample - loss: 0.5243 - acc: 0.7976 - val_loss: 0.5674 - val_acc: 0.7808
Epoch 36/50
20508/20508 [==============================] - 115s 6ms/sample - loss: 0.5369 - acc: 0.7955 - val_loss: 0.5716 - val_acc: 0.7926
Epoch 37/50
20508/20508 [==============================] - 106s 5ms/sample - loss: 0.5642 - acc: 0.7805 - val_loss: 0.6299 - val_acc: 0.7509
Epoch 38/50
20508/20508 [==============================] - 107s 5ms/sample - loss: 0.5895 - acc: 0.7741 - val_loss: 0.5804 - val_acc: 0.7868
Epoch 39/50
20508/20508 [==============================] - 107s 5ms/sample - loss: 0.5665 - acc: 0.7885 - val_loss: 0.5721 - val_acc: 0.7766
Epoch 40/50
20508/20508 [==============================] - 103s 5ms/sample - loss: 0.5416 - acc: 0.7907 - val_loss: 0.5702 - val_acc: 0.7785
Epoch 41/50
20508/20508 [==============================] - 109s 5ms/sample - loss: 0.5105 - acc: 0.8077 - val_loss: 0.5047 - val_acc: 0.8131
Epoch 42/50
20508/20508 [==============================] - 106s 5ms/sample - loss: 0.5207 - acc: 0.7996 - val_loss: 0.5472 - val_acc: 0.7911
Epoch 43/50
20508/20508 [==============================] - 106s 5ms/sample - loss: 0.5624 - acc: 0.7883 - val_loss: 0.5121 - val_acc: 0.8139
Epoch 44/50
20508/20508 [==============================] - 112s 5ms/sample - loss: 0.5093 - acc: 0.8098 - val_loss: 0.5132 - val_acc: 0.8160
Epoch 45/50
20508/20508 [==============================] - 120s 6ms/sample - loss: 0.4905 - acc: 0.8195 - val_loss: 0.5064 - val_acc: 0.8111
Epoch 46/50
20508/20508 [==============================] - 111s 5ms/sample - loss: 0.5065 - acc: 0.8035 - val_loss: 0.5669 - val_acc: 0.7669
Epoch 47/50
20508/20508 [==============================] - 119s 6ms/sample - loss: 0.5270 - acc: 0.7928 - val_loss: 0.5351 - val_acc: 0.7957
Epoch 48/50
20508/20508 [==============================] - 127s 6ms/sample - loss: 0.5013 - acc: 0.8059 - val_loss: 0.5121 - val_acc: 0.7991
Epoch 49/50
20508/20508 [==============================] - 118s 6ms/sample - loss: 0.4915 - acc: 0.8125 - val_loss: 0.5571 - val_acc: 0.7930
Epoch 50/50
20508/20508 [==============================] - 121s 6ms/sample - loss: 0.5058 - acc: 0.8022 - val_loss: 0.5867 - val_acc: 0.7598] - ETA: 32s - loss: 0.4962 - acc: 0.8071
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         (None, 25, 220)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 25, 256)           488448    
_________________________________________________________________
dense_15 (Dense)             (None, 25, 128)           32896     
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 5)                 645       
=================================================================
Total params: 521,989
Trainable params: 521,989
Non-trainable params: 0
_________________________________________________________________
None
Confusion matrix, without normalization
[[ 385    0   11   79    0]
 [   0  659  704   29 1087]
 [   0   67 3581   18   83]
 [   6   41  113 1662  386]
 [   0  129  390  141 4102]]