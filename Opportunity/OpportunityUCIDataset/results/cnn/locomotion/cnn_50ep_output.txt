Epoch 1/50
18625/18625 [==============================] - 84s 4ms/sample - loss: 0.6791 - acc: 0.8768 - val_loss: 0.2318 - val_acc: 0.9357
Epoch 2/50
18625/18625 [==============================] - 87s 5ms/sample - loss: 0.2619 - acc: 0.9291 - val_loss: 0.2103 - val_acc: 0.9456
Epoch 3/50
18625/18625 [==============================] - 88s 5ms/sample - loss: 0.2469 - acc: 0.9376 - val_loss: 0.2135 - val_acc: 0.9456
Epoch 4/50
18625/18625 [==============================] - 88s 5ms/sample - loss: 0.2179 - acc: 0.9434 - val_loss: 0.1862 - val_acc: 0.9559
Epoch 5/50
18625/18625 [==============================] - 89s 5ms/sample - loss: 0.2150 - acc: 0.9445 - val_loss: 0.1937 - val_acc: 0.9559
Epoch 6/50
18625/18625 [==============================] - 89s 5ms/sample - loss: 0.2041 - acc: 0.9479 - val_loss: 0.1801 - val_acc: 0.9559
Epoch 7/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.2012 - acc: 0.9494 - val_loss: 0.1855 - val_acc: 0.9556
Epoch 8/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1972 - acc: 0.9534 - val_loss: 0.1761 - val_acc: 0.9605
Epoch 9/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1917 - acc: 0.9550 - val_loss: 0.1856 - val_acc: 0.9556
Epoch 10/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1890 - acc: 0.9559 - val_loss: 0.1717 - val_acc: 0.9644
Epoch 11/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1895 - acc: 0.9559 - val_loss: 0.1701 - val_acc: 0.9645
Epoch 12/50
18625/18625 [==============================] - 88s 5ms/sample - loss: 0.1883 - acc: 0.9577 - val_loss: 0.1742 - val_acc: 0.9631
Epoch 13/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1914 - acc: 0.9562 - val_loss: 0.1710 - val_acc: 0.9653
Epoch 14/50
18625/18625 [==============================] - 93s 5ms/sample - loss: 0.1827 - acc: 0.9578 - val_loss: 0.1908 - val_acc: 0.9605
Epoch 15/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1952 - acc: 0.9562 - val_loss: 0.1795 - val_acc: 0.9620
Epoch 16/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1831 - acc: 0.9599 - val_loss: 0.1734 - val_acc: 0.9653
Epoch 17/50
18625/18625 [==============================] - 92s 5ms/sample - loss: 0.1823 - acc: 0.9600 - val_loss: 0.1920 - val_acc: 0.9600
Epoch 18/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1762 - acc: 0.9636 - val_loss: 0.1759 - val_acc: 0.9645
Epoch 19/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1903 - acc: 0.9604 - val_loss: 0.1823 - val_acc: 0.9634
Epoch 20/50
18625/18625 [==============================] - 92s 5ms/sample - loss: 0.1806 - acc: 0.9627 - val_loss: 0.1866 - val_acc: 0.9634
Epoch 21/50
18625/18625 [==============================] - 92s 5ms/sample - loss: 0.1796 - acc: 0.9627 - val_loss: 0.1808 - val_acc: 0.9642
Epoch 22/50
18625/18625 [==============================] - 93s 5ms/sample - loss: 0.1824 - acc: 0.9618 - val_loss: 0.2067 - val_acc: 0.9628
Epoch 23/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1831 - acc: 0.9646 - val_loss: 0.1756 - val_acc: 0.9706
Epoch 24/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1802 - acc: 0.9645 - val_loss: 0.1835 - val_acc: 0.9661
Epoch 25/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1739 - acc: 0.9660 - val_loss: 0.1805 - val_acc: 0.9656
Epoch 26/50
18625/18625 [==============================] - 89s 5ms/sample - loss: 0.1760 - acc: 0.9661 - val_loss: 0.1862 - val_acc: 0.9653
Epoch 27/50
18625/18625 [==============================] - 89s 5ms/sample - loss: 0.1763 - acc: 0.9656 - val_loss: 0.1809 - val_acc: 0.9680
Epoch 28/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1725 - acc: 0.9671 - val_loss: 0.1718 - val_acc: 0.9673
Epoch 29/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1748 - acc: 0.9656 - val_loss: 0.1870 - val_acc: 0.9660
Epoch 30/50
18625/18625 [==============================] - 89s 5ms/sample - loss: 0.1718 - acc: 0.9688 - val_loss: 0.1821 - val_acc: 0.9676
Epoch 31/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1722 - acc: 0.9686 - val_loss: 0.1855 - val_acc: 0.9674
Epoch 32/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1710 - acc: 0.9689 - val_loss: 0.1772 - val_acc: 0.9670
Epoch 33/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1673 - acc: 0.9687 - val_loss: 0.2010 - val_acc: 0.9655
Epoch 34/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1686 - acc: 0.9670 - val_loss: 0.1772 - val_acc: 0.9699
Epoch 35/50
18625/18625 [==============================] - 95s 5ms/sample - loss: 0.1847 - acc: 0.9652 - val_loss: 0.1819 - val_acc: 0.9692
Epoch 36/50
18625/18625 [==============================] - 93s 5ms/sample - loss: 0.1770 - acc: 0.9680 - val_loss: 0.1766 - val_acc: 0.9709
Epoch 37/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1744 - acc: 0.9690 - val_loss: 0.1805 - val_acc: 0.9698
Epoch 38/50
18625/18625 [==============================] - 89s 5ms/sample - loss: 0.1615 - acc: 0.9714 - val_loss: 0.1812 - val_acc: 0.9654
Epoch 39/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1697 - acc: 0.9689 - val_loss: 0.1732 - val_acc: 0.9700
Epoch 40/50
18625/18625 [==============================] - 89s 5ms/sample - loss: 0.1653 - acc: 0.9708 - val_loss: 0.1782 - val_acc: 0.9693
Epoch 41/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1616 - acc: 0.9718 - val_loss: 0.1688 - val_acc: 0.9718
Epoch 42/50
18625/18625 [==============================] - 93s 5ms/sample - loss: 0.1612 - acc: 0.9726 - val_loss: 0.1765 - val_acc: 0.9685
Epoch 43/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1622 - acc: 0.9713 - val_loss: 0.1783 - val_acc: 0.9708
Epoch 44/50
18625/18625 [==============================] - 94s 5ms/sample - loss: 0.1601 - acc: 0.9726 - val_loss: 0.1819 - val_acc: 0.9685
Epoch 45/50
18625/18625 [==============================] - 94s 5ms/sample - loss: 0.1592 - acc: 0.9729 - val_loss: 0.1765 - val_acc: 0.9716
Epoch 46/50
18625/18625 [==============================] - 92s 5ms/sample - loss: 0.1647 - acc: 0.9703 - val_loss: 0.1752 - val_acc: 0.9709
Epoch 47/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1586 - acc: 0.9730 - val_loss: 0.1687 - val_acc: 0.9721
Epoch 48/50
18625/18625 [==============================] - 92s 5ms/sample - loss: 0.1543 - acc: 0.9744 - val_loss: 0.1767 - val_acc: 0.9692
Epoch 49/50
18625/18625 [==============================] - 91s 5ms/sample - loss: 0.1533 - acc: 0.9739 - val_loss: 0.1695 - val_acc: 0.9710
Epoch 50/50
18625/18625 [==============================] - 90s 5ms/sample - loss: 0.1527 - acc: 0.9723 - val_loss: 0.1826 - val_acc: 0.9696
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 25, 220, 1)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 13, 110, 32)       320       
_________________________________________________________________
batch_normalization_v1_3 (Ba (None, 13, 110, 32)       128       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 6, 55, 32)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 6, 55, 32)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 3, 28, 64)         18496     
_________________________________________________________________
batch_normalization_v1_4 (Ba (None, 3, 28, 64)         256       
_________________________________________________________________
dropout_3 (Dropout)          (None, 3, 28, 64)         0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 2, 14, 128)        73856     
_________________________________________________________________
batch_normalization_v1_5 (Ba (None, 2, 14, 128)        512       
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 1, 7, 128)         0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 1, 7, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 896)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 896)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              918528    
_________________________________________________________________
dropout_6 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 4)                 4100      
=================================================================
Total params: 1,016,196
Trainable params: 1,015,748
Non-trainable params: 448
_________________________________________________________________
None
Confusion matrix, without normalization
[[ 619    0    1    4]
 [   0 5391  202   19]
 [   0  132 2849    1]
 [  10    8    1 3180]]