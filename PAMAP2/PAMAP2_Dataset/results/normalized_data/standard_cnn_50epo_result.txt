read h5 file....
(2814, 25, 40)
Train on 2814 samples, validate on 1877 samples
Epoch 1/50
2814/2814 [==============================] - 4s 2ms/sample - loss: 1.0658 - acc: 0.6912 - val_loss: 2.3977 - val_acc: 0.2211
Epoch 2/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.4726 - acc: 0.8738 - val_loss: 0.7037 - val_acc: 0.7869
Epoch 3/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.3542 - acc: 0.9108 - val_loss: 0.4987 - val_acc: 0.8625
Epoch 4/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.3078 - acc: 0.9250 - val_loss: 0.3881 - val_acc: 0.8972
Epoch 5/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.2798 - acc: 0.9360 - val_loss: 0.2914 - val_acc: 0.9334
Epoch 6/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1886 - acc: 0.9620 - val_loss: 0.2446 - val_acc: 0.9467
Epoch 7/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.2015 - acc: 0.9581 - val_loss: 0.2485 - val_acc: 0.9451
Epoch 8/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1827 - acc: 0.9662 - val_loss: 0.3308 - val_acc: 0.9238
Epoch 9/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1667 - acc: 0.9694 - val_loss: 0.2672 - val_acc: 0.9377
Epoch 10/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1556 - acc: 0.9741 - val_loss: 0.3738 - val_acc: 0.9222
Epoch 11/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1688 - acc: 0.9677 - val_loss: 0.3899 - val_acc: 0.9185
Epoch 12/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1770 - acc: 0.9701 - val_loss: 0.2577 - val_acc: 0.9531
Epoch 13/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1357 - acc: 0.9829 - val_loss: 0.2592 - val_acc: 0.9510
Epoch 14/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1358 - acc: 0.9805 - val_loss: 0.3229 - val_acc: 0.9286
Epoch 15/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1378 - acc: 0.9797 - val_loss: 0.2502 - val_acc: 0.9632
Epoch 16/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1264 - acc: 0.9851 - val_loss: 0.3017 - val_acc: 0.9441
Epoch 17/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1331 - acc: 0.9819 - val_loss: 0.3172 - val_acc: 0.9366
Epoch 18/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1578 - acc: 0.9748 - val_loss: 0.3195 - val_acc: 0.9377
Epoch 19/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1538 - acc: 0.9776 - val_loss: 0.3020 - val_acc: 0.9393
Epoch 20/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1180 - acc: 0.9883 - val_loss: 0.2617 - val_acc: 0.9536
Epoch 21/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.0988 - acc: 0.9943 - val_loss: 0.2781 - val_acc: 0.9521
Epoch 22/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1116 - acc: 0.9893 - val_loss: 0.3213 - val_acc: 0.9462
Epoch 23/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1381 - acc: 0.9826 - val_loss: 0.3418 - val_acc: 0.9489
Epoch 24/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1341 - acc: 0.9822 - val_loss: 0.3273 - val_acc: 0.9451
Epoch 25/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1460 - acc: 0.9805 - val_loss: 0.3131 - val_acc: 0.9441
Epoch 26/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1389 - acc: 0.9851 - val_loss: 0.4167 - val_acc: 0.9196
Epoch 27/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1267 - acc: 0.9854 - val_loss: 0.3254 - val_acc: 0.9382
Epoch 28/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1167 - acc: 0.9890 - val_loss: 0.2520 - val_acc: 0.9574
Epoch 29/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1223 - acc: 0.9851 - val_loss: 0.3187 - val_acc: 0.9414
Epoch 30/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1318 - acc: 0.9854 - val_loss: 0.3510 - val_acc: 0.9398
Epoch 31/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1258 - acc: 0.9865 - val_loss: 0.3609 - val_acc: 0.9419
Epoch 32/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1345 - acc: 0.9844 - val_loss: 0.3399 - val_acc: 0.9435
Epoch 33/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1192 - acc: 0.9883 - val_loss: 0.3314 - val_acc: 0.9494
Epoch 34/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1176 - acc: 0.9911 - val_loss: 0.3281 - val_acc: 0.9478
Epoch 35/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1160 - acc: 0.9911 - val_loss: 0.3301 - val_acc: 0.9478
Epoch 36/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1331 - acc: 0.9847 - val_loss: 0.2891 - val_acc: 0.9499
Epoch 37/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1365 - acc: 0.9833 - val_loss: 0.3386 - val_acc: 0.9478
Epoch 38/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1208 - acc: 0.9911 - val_loss: 0.3096 - val_acc: 0.9515
Epoch 39/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1181 - acc: 0.9886 - val_loss: 0.2904 - val_acc: 0.9563
Epoch 40/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1070 - acc: 0.9932 - val_loss: 0.4330 - val_acc: 0.9297
Epoch 41/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1147 - acc: 0.9918 - val_loss: 0.2930 - val_acc: 0.9552
Epoch 42/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1076 - acc: 0.9936 - val_loss: 0.3122 - val_acc: 0.9483
Epoch 43/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1139 - acc: 0.9900 - val_loss: 0.3968 - val_acc: 0.9382
Epoch 44/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1457 - acc: 0.9837 - val_loss: 0.3801 - val_acc: 0.9366
Epoch 45/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1333 - acc: 0.9819 - val_loss: 0.3685 - val_acc: 0.9387
Epoch 46/50
2814/2814 [==============================] - 4s 1ms/sample - loss: 0.1684 - acc: 0.9762 - val_loss: 0.4323 - val_acc: 0.9323
Epoch 47/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1430 - acc: 0.9854 - val_loss: 0.3327 - val_acc: 0.9462
Epoch 48/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1364 - acc: 0.9876 - val_loss: 0.3286 - val_acc: 0.9441
Epoch 49/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1152 - acc: 0.9925 - val_loss: 0.3610 - val_acc: 0.9387
Epoch 50/50
2814/2814 [==============================] - 3s 1ms/sample - loss: 0.1146 - acc: 0.9925 - val_loss: 0.3070 - val_acc: 0.9515
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 25, 40, 1)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 13, 20, 32)        320       
_________________________________________________________________
batch_normalization_v1_3 (Ba (None, 13, 20, 32)        128       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 6, 10, 32)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 3, 5, 64)          18496     
_________________________________________________________________
batch_normalization_v1_4 (Ba (None, 3, 5, 64)          256       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 2, 3, 128)         73856     
_________________________________________________________________
batch_normalization_v1_5 (Ba (None, 2, 3, 128)         512       
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 128)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              132096    
_________________________________________________________________
dropout_3 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 12)                12300     
=================================================================
Total params: 237,964
Trainable params: 237,516
Non-trainable params: 448
_________________________________________________________________
None
Confusion matrix, without normalization
[[ 39   0   0   0   0   1   0   1   0   0   0   0]
 [  0 173   0   1   0   0   0   0   0   0   2   0]
 [  0   0 159  15   0   0   0   0   0   0   7   0]
 [  0   0   0 186   0   0   0   0   0   0   0   5]
 [  0   0   0   0 235   0   0   2   1   3   0   0]
 [  0   0   0   2   3  87   0   0   0   0   0   0]
 [  0   0   0   0   0   0 139   0   0   0   1   0]
 [  1   0   0   1   4   0   0 189   0   1   0   0]
 [  0   2   0   0   8   0   0   4  93   6   1   0]
 [  1   0   0   0   3   0   0   0   4  88   5   0]
 [  0   0   0   0   0   0   1   0   0   0 161   1]
 [  0   0   0   1   0   0   0   0   0   0   3 237]]